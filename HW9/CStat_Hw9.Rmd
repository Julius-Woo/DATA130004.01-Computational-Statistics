---
title: "Computational Statistics HW9"
author: "吴嘉骜 21307130203"
date: "2023-12-10"
output:
  html_document:
    self_contained: yes
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: no
      smooth_scroll: no
      number_sections: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{=html}
<style type="text/css">
h1.title{
  font-size: 38px;
  color: DarkRed;
  text-align: center;
}
h4.author{
  font-size: 18px;
  color: DarkRed;
  text-align: center;
}
h4.date {
  font-size: 18px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;
  text-align: center;
}

</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, cache = TRUE, message = TRUE, fig.align = "center")
```
## ex 9.1
Repeat Example 9.1 for the target distribution Rayleigh($\sigma$ = 2). Compare the performance of the Metropolis-Hastings sampler for Example 9.1 and this problem. In particular, what differences are obvious from the plot corresponding to Figure 9.1?

Solution.

```{r}
# rayleigh distribution
f <- function(x, sigma) {
  if (x < 0) {
    return(0)
  } else {
    return(x / sigma^2 * exp(-x^2 / (2 * sigma^2)))
  }
}

m <- 10000
sigma <- 2
x <- numeric(m)
x[1] <- rchisq(1, df=1)
k <- 0
u <- runif(m)

for(i in 2:m){
  xt <- x[i-1]
  y <- rchisq(1, df=xt)
  num <- f(y, sigma) * dchisq(xt, df = y)
  den <- f(xt, sigma) * dchisq(y, df = xt)
  if (u[i] <= num/den)
    x[i] <- y
  else {
    x[i] <- xt
    k <- k + 1  # y is rejected
  }
}
print(k)
index <- 5000:5500
plot(index, x[index], type="l", xlab="iteration", ylab="x", main="")
```

There are more rejections in this problem than in Example 9.1, with more than half of the candidates being rejected. So this chain is less efficient than when $\sigma=4$. From the plot, we can see that there are longer and more often horizontal lines, which indicates continuous rejections.

## ex 9.2
Repeat Example 9.1 using the proposal distribution $Y \sim \text{Gamma}(X_t, 1)$ (shape parameter $X_t$ and rate parameter 1).

Solution.

```{r}
# rayleigh distribution
f <- function(x, sigma) {
  if (x < 0) {
    return(0)
  } else {
    return(x / sigma^2 * exp(-x^2 / (2 * sigma^2)))
  }
}

m <- 10000
sigma <- 4
x <- numeric(m)
x[1] <- 1
k <- 0
u <- runif(m)

for(i in 2:m){
  xt <- x[i-1]
  y <- rgamma(1, xt, 1)
  num <- f(y, sigma) * dgamma(xt, y, 1)
  den <- f(xt, sigma) * dgamma(y, xt, 1)
  if (u[i] <= num/den)
    x[i] <- y
  else {
    x[i] <- xt
    k <- k + 1  # y is rejected
  }
}
print(k)
index <- 5000:5500
plot(index, x[index], type="l", xlab="iteration", ylab="x", main="")
```

This chain seems more efficient than that generated by the $\chi^2$ proposal distribution.

## ex 9.3
Use the Metropolis-Hastings sampler to generate random variables from a standard Cauchy distribution. Discard the first 1000 of the chain, and compare the deciles of the generated observations with the deciles of the standard Cauchy distribution (see $\texttt{qcauchy}$ or $\texttt{qt}$ with df=1). Recall that a Cauchy$(\theta, \eta)$ distribution has density function
$$
f(x) = \frac{1}{ \theta \pi \left(1 + \left(\frac{x - \eta}{\theta}\right)^2\right)}, \quad -\infty < x < \infty, \theta > 0.
$$
The standard Cauchy has the Cauchy$(\theta = 1, \eta = 0)$ density. (Note that the standard Cauchy density is equal to the Student t density with one degree of freedom.)

Solution.

For proposal distribution, we use $Y \sim \text{Normal}(X_t, 1)$. Note that it is symmetric, and cancelling the normalizing constants, we have
$$
r(x_t,y) = \frac{f(y)}{f(x_t)} = \frac{1}{\pi \left(1 + \left(\frac{y}{1}\right)^2\right)} \frac{\pi \left(1 + \left(\frac{x_t}{1}\right)^2\right)}{1} = \frac{1 + x_t^2}{1 + y^2}.
$$

```{r}
m <- 10000
sigma <- 4
x <- numeric(m)
x[1] <- rnorm(1, 0, sigma)
k <- 0
u <- runif(m)

for(i in 2:m){
  xt <- x[i-1]
  y <- rnorm(1, xt, sigma)
  num <- 1 + xt^2
  den <- 1 + y^2
  if (u[i] <= num/den)
    x[i] <- y
  else {
    x[i] <- xt
    k <- k + 1  # y is rejected
  }
}
print(k)
burnin <- 1000
x <- x[(burnin+1):m]
p <- seq(0.1, 0.9, 0.1)
q <- quantile(x, p)
round(rbind(q, qcauchy(p)), 3)

# QQ plot
p <- ppoints(100)
q <- quantile(x, p)
plot(qcauchy(p), q, xlab="Theoretical quantiles", ylab="Sample quantiles", main="")
abline(0, 1)
```

From the numerical results and the QQ plot, we can see that the deciles of the generated chain are close to that of standard Cauchy distribution in the middle, but deviate a lot in the lower and upper tails.

## ex 9.4
Implement a random walk Metropolis sampler for generating the standard Laplace distribution (see Exercise 3.2). For the increment, simulate from a normal distribution. Compare the chains generated when different variances are used for the proposal distribution. Also, compute the acceptance rates of each chain.

Solution.

The standard Laplace distribution has density function
$$
f(x) = \frac{1}{2} \exp(-|x|), \quad -\infty < x < \infty.
$$
For proposal distribution, we use $Y \sim \text{Normal}(X_t, \sigma^2)$, and the acceptance probability is
$$
r(x_t,y) = \frac{f(y)}{f(x_t)} = \frac{1}{2} \exp(-|y|) \frac{1}{2} \exp(-|x_t|) = \exp(-|y| + |x_t|).
$$


```{r}
# random walk metropolis sampler
rw <- function(m, x0, sigma){
  x <- numeric(m)
  x[1] <- x0
  k <- 0
  u <- runif(m)
  for(i in 2:m){
    xt <- x[i-1]
    y <- rnorm(1, xt, sigma)
    if (u[i] <= exp(-abs(y) + abs(xt)))
      x[i] <- y
    else {
      x[i] <- xt
      k <- k + 1  # y is rejected
    }
  }
  return(list(x=x, k=k))
}

# generate chains with different variances
sigma <- c(0.5, 1, 2, 4)
m <- 5000
x0 <- rnorm(1, 0, 1)
rw1 <- rw(m, x0, sigma[1])
rw2 <- rw(m, x0, sigma[2])
rw3 <- rw(m, x0, sigma[3])
rw4 <- rw(m, x0, sigma[4])

# plot chains
burnin <- 500
index <- (burnin+1):m
par(mfrow=c(2,2))
plot(index, rw1$x[index], type="l", xlab="index", ylab="rw1 x", main=paste("sigma =", sigma[1]))
plot(index, rw2$x[index], type="l", xlab="index", ylab="rw2 x", main=paste("sigma =", sigma[2]))
plot(index, rw3$x[index], type="l", xlab="index", ylab="rw3 x", main=paste("sigma =", sigma[3]))
plot(index, rw4$x[index], type="l", xlab="index", ylab="rw4 x", main=paste("sigma =", sigma[4]))

# QQ plots
par(mfrow=c(2,2))
p <- ppoints(100)
y <- qexp(p,1)
z <- c(-rev(y), y)
q1 <- quantile(rw1$x[index], p)
qqplot(z, q1, xlab="Theoretical quantiles", ylab="Sample quantiles", main=paste("sigma =", sigma[1]))
abline(0, 1)
q2 <- quantile(rw2$x[index], p)
qqplot(z, q2, xlab="Theoretical quantiles", ylab="Sample quantiles", main=paste("sigma =", sigma[2]))
abline(0, 1)
q3 <- quantile(rw3$x[index], p)
qqplot(z, q3, xlab="Theoretical quantiles", ylab="Sample quantiles", main=paste("sigma =", sigma[3]))
abline(0, 1)
q4 <- quantile(rw4$x[index], p)
qqplot(z, q4, xlab="Theoretical quantiles", ylab="Sample quantiles", main=paste("sigma =", sigma[4]))
abline(0, 1)


# acceptance rates
library(scales)
cat("acceptance rates:", percent(1-rw1$k/m,.01), percent(1-rw2$k/m,.01), percent(1-rw3$k/m,.01), percent(1-rw4$k/m,.01))
```

From the plots, we can see that each of the chains have converged to the target distribution. Chains with smaller variance have larger acceptance rates, thus are more efficient.

## ex 9.5
What effect, if any, does the width $w$ have on the mixing of the chain in Example 9.5? Repeat the simulation keeping the random number seed fixed, trying different proposal distributions based on the random increments from Uniform$(−w, w)$, varying $w$.

Solution.

```{r}
b <- .2 # actual value of beta
m <- 5000
burn <- 1000 # burn-in time
days <- 250

# use the same seed
set.seed(123)

# generate the observed frequencies of winners
i <- sample(1:5, size=days, replace=TRUE, prob=c(1, 1-b, 1-2*b, 2*b, b))
win <- tabulate(i)

# target distribution
prob <- function(y, win) {
if (y < 0 || y >= 0.5)
return (0)
else
return((1/3)^win[1] *
((1-y)/3)^win[2] * ((1-2*y)/3)^win[3] *
((2*y)/3)^win[4] * (y/3)^win[5])
}

W <- c(0.05, 0.1, 0.2, 0.4)
X <- matrix(0, nrow=m, ncol=4)
x <- numeric(m)
k <- numeric(4)

# random walk metropolis sampler
for (j in 1:4) {
  w <- W[j]
  u <- runif(m)
  v <- runif(m, -w, w)
  x[1] <- .25
  for (i in 2:m) {
    y <- x[i-1] + v[i]
    if (u[i] <= prob(y, win) / prob(x[i-1], win))
      x[i] <- y
    else{
      x[i] <- x[i-1]
      k[j] <- k[j] + 1
    }
  }
  X[,j] <- x
}

par(mfrow = c(2, 2))
for (j in 1:4) {
  x <- X[(m - 500):m, j]
  plot((m - 500):m, x, type = "l", xlab = j, ylab = "x", main = paste("w =", W[j]))
  abline(h = b, v = burn, lty = 3, col = "red")
}

cat("rejection rates:", k/m)
```

Form the plots, we observe that the chains are close to the actual value of $\beta$ after burn-in time. Both the graphs and numerical results indicate that smaller $w$ leads to lower rejection rates and better mixing of the chain, which proves efficiency.