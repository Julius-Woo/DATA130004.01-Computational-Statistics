---
title: "Computational Statistics HW5"
author: "吴嘉骜 21307130203"
date: "2023-11-9"
output:
  html_document:
    self_contained: yes
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: no
      smooth_scroll: no
      number_sections: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{=html}
<style type="text/css">
h1.title{
  font-size: 38px;
  color: DarkRed;
  text-align: center;
}
h4.author{
  font-size: 18px;
  color: DarkRed;
  text-align: center;
}
h4.date {
  font-size: 18px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;
  text-align: center;
}

</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, cache = TRUE, message = TRUE, fig.align = "center")
```
## ex 6.1
Estimate the MSE of the level $k$ trimmed means for random samples of size
20 generated from a standard Cauchy distribution. (The target parameter $\theta$
is the center or median; the expected value does not exist.) Summarize the
estimates of MSE in a table for $k = 1, 2, \ldots , 9$.

Solution.

````{r}
n <- 20
m <- 1000
mse <- numeric(9)
for (k in 1:9){
  tmean <- numeric(m)
  for (i in 1:m){
    x <- sort(rcauchy(n))
    tmean[i] <- sum(x[(k+1): (n-k)])/(n - 2 * k)
  }
  mse[k] <- mean((tmean-0)^2)
}

mse <- as.data.frame(cbind(1:9, mse))
names(mse) <- list("k", "MSE")
print(mse)
```

## ex 6.4
Suppose that $X_1, \ldots , X_n$ are a random sample from a lognormal 
distribution with unknown parameters. Construct a 95% confidence interval for
the parameter $\mu$. Use a Monte Carlo method to obtain an empirical estimate
of the confidence level.

Solution.

Transform $X$ to $Y \sim N(\mu, \sigma^2)$ by letting $Y = \log(X)$, then we have
$\hat{\mu} = \bar{Y} = \sum\limits_{i=1}^n\log(X_i)/n$ and 
$s^2 = \frac{1}{n-1}\sum\limits_{i=1}^n(Y_i - \bar{Y})^2 = \frac{1}{n-1}\sum\limits_{i=1}^n(\log(X_i) - \bar{\log(X)})^2$.

Then test statistic is $\frac{\sqrt{n}(\hat{\mu} - \mu)}{s} \sim t_{(n-1)}$.

The confidence interval is $\hat{\mu} \pm t_{n-1}(\frac{\alpha}{2})\cdot s/\sqrt{n}$.

````{r}
n <- 40
alpha <- 0.05
CI <- replicate(1000, expr = {
  x <- rlnorm(n)
  y <- log(x)
  mu <- mean(y)
  s <- sd(y)
  i = qt(1 - alpha/2, df = n - 1) * s / sqrt(n)
  c(mu - i, mu + i)
})
LCL = CI[1,]
UCL = CI[2,]
coverage <- mean(LCL < 0 & UCL > 0)
print(coverage)
```

## ex 6.5
Suppose a 95% symmetric $t$-interval is applied to estimate a mean, but the
sample data are non-normal. Then the probability that the confidence interval
covers the mean is not necessarily equal to 0.95. Use a Monte Carlo experiment
to estimate the coverage probability of the $t$-interval for random samples of
$\chi^2(2)$ data with sample size $n = 20$. Compare your $t$-interval results with the
simulation results in Example 6.4. (The $t$-interval should be more robust to
departures from normality than the interval for variance.)

Solution.

````{r}
n <- 20
alpha <- 0.05
CI <- replicate(1000, expr={
  x <- rchisq(n, df = 2)
  mu <- mean(x)
  s <- sd(x)
  i = qt(1 - alpha/2, df = n - 1) * s / sqrt(n)
  c(mu - i, mu + i)
})
LCL = CI[1,]
UCL = CI[2,]
coverage <- mean(LCL < 2 & UCL > 2)
print(coverage)
```
We can observe that the confidence level is lower than 95%, whereas in Example 6.4, it is almost equal to the preset level.


## ex 6.9
Let $X$ be a non-negative random variable with $\mu = \text{E}[X] < \infty$. For a random
sample $x_1, \ldots , x_n$ from the distribution of $X$, the Gini ratio is defined by
$$
G = \frac{1}{2n^2\mu}\sum\limits_{i=1}^n\sum\limits_{j=1}^n|x_i - x_j|.
$$
The Gini ratio is applied in economics to measure inequality in income distribution. 
Note that $G$ can be written in terms of the order statistics $x_{(i)}$ as
$$
G = \frac{1}{n^2\mu}\sum\limits_{i=1}^n(2i-n-1)x_{(i)}.
$$
If the mean is unknown, let $\hat{G}$ be the statistic $G$ with $\mu$ replaced by $\hat{x}$. Estimate
by simulation the mean, median and deciles of $\hat{G}$ if $X$ is standard lognormal.
Repeat the procedure for the uniform distribution and Bernoulli(0.1). Also
construct density histograms of the replicates in each case.

Solution.

````{r}
Gini <- function(x){
  n <- length(x)
  mu <- mean(x)
  x <- sort(x)
  i <- 2*(1:n) - n - 1
  G <- sum(i * x) / (n^2 * mu)
  return(G)
}
n <- 100
m <- 10000
g_lognormal <- replicate(m, Gini(rlnorm(n)))
g_uniform <- replicate(m, Gini(runif(n)))
g_bernoulli <- replicate(m, Gini(rbinom(n, size = 1, prob = 0.1)))
gini <- data.frame(g_lognormal, g_uniform, g_bernoulli)
summary(gini) # mean, median
apply(gini, 2, quantile, probs = seq(0.1, 0.9, by = 0.1)) # deciles

# histogram
par(mfrow = c(1, 3))
hist(g_lognormal, freq = FALSE, main = "lognormal", xlim=c(0,1))
hist(g_uniform, freq = FALSE, main = "uniform", xlim=c(0,1))
hist(g_bernoulli, freq = FALSE, main = "bernoulli", xlim=c(0,1))
```

## ex 6.10
Construct an approximate 95% confidence interval for the Gini ratio $\gamma = \text{E}[G]$
if $X$ is lognormal with unknown parameters. Assess the coverage rate of the
estimation procedure with a Monte Carlo experiment.

Solution.

According to Aitchison and Brown (1958), if a population is log-normally distributed, then its Gini coefficient is given by $\gamma = 2\Phi(\sigma/√2)-1$, where $\sigma$ is the standard deviation of lognormal distribution and $\Phi$ is the cumulative distribution function of the standard normal distribution. In view of this, we can estimate the Gini ratio by $\hat{\gamma} = 2\Phi(\hat{\sigma}/√2)-1$, where $\hat{\sigma}$ is the MLE of $\sigma$. As $\Phi(x)$ is a monotone increasing function, $\hat{\gamma}$ is an MLE of $\gamma$. Based on the asymptotic normality, we can construct the confidence interval as $\hat{\gamma} \pm z_{\alpha/2}\cdot \text{SE}(\hat{\gamma})$.

````{r}
# calculate the true Gini coefficient for a lognormal distribution
trueGiniLogn <- function(sigma) {
  2 * pnorm(sigma / sqrt(2)) - 1
}

sigma <- 1  # standard deviation of lognormal distribution
g0 <- trueGiniLogn(sigma)
print(g0)

# estimate the Gini coefficient by simulation
n <- 1000
m <- 1000
alpha <- 0.05

sigma2hat <- replicate(m, expr={
  x <- rlnorm(n, sdlog = sigma)
  mean((log(x) - mean(log(x)))^2)
  })
gammahat <- 2 * pnorm(sqrt(sigma2hat / 2)) - 1
sde <- sd(gammahat)
LCL <- gammahat - qnorm(1 - alpha/2) * sde
UCL <- gammahat + qnorm(1 - alpha/2) * sde
coverage <- mean(LCL < g0 & UCL > g0)
print(coverage)
```


## Sample Variance Property
Suppose $X_1, . . . , X_n$ are i.i.d. samples from a normal distribution $N(\mu, \sigma^2), n\geq 2$.
Prove that $\sum\limits_{i=1}^n (Xi − \bar{X})^2/\sigma^2$ follows a $\chi^2(n-1)$ distribution and it is independent
with the sample mean $\bar{X}$.

Proof:

Construct an orthogonal matrix $A$, where the first row is $a_1^T = [\frac{1}{\sqrt{n}}, \frac{1}{\sqrt{n}}, \ldots, \frac{1}{\sqrt{n}}]$.

Let $X = [X_1, X_2, \ldots, X_n]^T$, then $X$ satisfies multivariate normal distribution $N(\mu \mathbf{1}_n, \sigma^2I)$ since $X_i$ are i.i.d. samples from $N(\mu, \sigma^2)$.

Denote $Z = AX$, also follows multivariate normal distribution $N(A\mu \mathbf{1}_n, \sigma^2I)$ since $A$ is orthogonal.
Then we have $Z_1, \ldots, Z_n$ are independent.

From the first row of $A$, we know that $\bar{X} = \frac{1}{n}\sum\limits_{i=1}^n X_i =Z_1/\sqrt{n}$.
In addition, $Z^{\top}Z = X^{\top}A^{\top}AX=X^{\top}X$, so $\sum\limits_{i=1}^n (X_i - \bar{X})^2 = \sum\limits_{i=1}^n X_i^2 -  n\bar{X}^2 = X^{\top}X - (\sqrt{n}\bar{x})^2 = Z^{\top}Z - Z_1^2 = \sum\limits_{i=2}^n Z_i^2$.

Since $Z_1, \ldots, Z_n$ are independent, we have $\sum\limits_{i=1}^n (X_i - \bar{X})^2 = \sum\limits_{i=2}^n Z_i^2$ independent with $\bar{X} = Z_1/\sqrt{n}$. 

As $A$ is orthogonal, we have $a_i^{\top}a_1 = 0$ for $i \geq 2$, so $a_i^{\top}\mathbf{1}_n = 0$.
Then $\text{E}Z_i = \mu a_i^{\top}\mathbf{1}_N = 0$ for $i \geq 2$, which leads to $Z_i \sim N(0, \sigma^2)$ for $i \geq 2$.
That follows $\sum\limits_{i=1}^n (Xi − \bar{X})^2/\sigma^2 = \sum\limits_{i=2}^n Z_i^2/\sigma^2 \sim \chi^2(n-1)$.